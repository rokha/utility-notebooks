{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webpage data scraping with Mercury, Requests and Beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rokha/.local/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import config\n",
    "import pathlib\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'mobile'\n",
    "folder = 'models/' + model\n",
    "\n",
    "# create a sources.txt file with one line per url within the model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebParser:\n",
    "    def __init__(self):\n",
    "        self.env_variables = config.Config().get()\n",
    "        self.parse_api_key = str(self.env_variables['mercury_api_key'])\n",
    "        self.parse_api_url = 'https://mercury.postlight.com/parser?url='\n",
    "\n",
    "    def prepare_payload(self, url):\n",
    "        payload = {'Content-Type': 'application/json',\n",
    "                   'x-api-key': self.parse_api_key}\n",
    "        return payload\n",
    "\n",
    "    def parse(self, url):\n",
    "        payload = self.prepare_payload(url)\n",
    "        request_url = self.parse_api_url + url\n",
    "        try:\n",
    "            response = requests.get(request_url, headers=payload)\n",
    "            response = response.json()['content']\n",
    "        except ValueError:\n",
    "            response = response.content\n",
    "        except Exception as e:\n",
    "            response = str(e)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileStorage:\n",
    "    def __init__(self, folder, path):\n",
    "        self.env_variables = config.Config().get()\n",
    "        self.folder = folder\n",
    "        self.path = path\n",
    "        \n",
    "    def store(self, data):\n",
    "        pathlib.Path(self.folder + '/data/' + self.path).mkdir(parents=True, exist_ok=True)\n",
    "        fp = open(self.folder + '/data/' + self.path + data['uid'] + '.json', 'w')\n",
    "        fp.write(json.dumps(data))\n",
    "        \n",
    "    def storeInCSV(self, uid, data):\n",
    "        pathlib.Path(self.folder + '/data/' + self.path).mkdir(parents=True, exist_ok=True)\n",
    "        with open(self.folder + '/data/' + self.path + uid + '.csv', 'w', encoding='utf-8') as csvfile:\n",
    "            spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                    quotechar='\"')\n",
    "            for row in data:\n",
    "                spamwriter.writerow([row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextExtractor:\n",
    "    def __init__(self):\n",
    "        self.env_variables = config.Config().get()\n",
    "        \n",
    "    def HTMLtoLines(self, html):\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "#         paragraphs = soup.find_all('p')\n",
    "        text = soup.get_text()\n",
    "        sentences = sent_tokenize(text)\n",
    "        return sentences\n",
    "    \n",
    "    def SentenceToWords(self, sentence):\n",
    "        words = word_tokenize(sentence)\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Download:\n",
    "    def __init__(self, folder):\n",
    "        self.env_variables = config.Config().get()\n",
    "        self.folder = folder\n",
    "        self.url_regex = re.compile(\n",
    "        r'^(?:http|ftp)s?://' # http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "        r'localhost|' #localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "        r'(?::\\d+)?' # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "        \n",
    "    def start(self):\n",
    "        with open(self.folder + '/sources.txt') as sources:\n",
    "            url = sources.readline()\n",
    "            while url:\n",
    "                url = url.strip()\n",
    "                if re.match(self.url_regex, url) is None:\n",
    "                    print('faulty url: ' + url)\n",
    "                    url = sources.readline()\n",
    "                    continue\n",
    "                data = dict()\n",
    "#                 print('fetching ' + url)\n",
    "                data['content'] = WebParser().parse(url)\n",
    "                data['uid'] = url.split('/')[-1]\n",
    "                FileStorage(self.folder, 'html/').store(data)\n",
    "                sentences = TextExtractor().HTMLtoLines(data['content'])\n",
    "                FileStorage(self.folder, 'csv/').storeInCSV(data['uid'], sentences)\n",
    "#                 print('fetched and saved csv and html')\n",
    "                url = sources.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Download(folder).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiled csv of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRows = []\n",
    "directory = os.getcwd() + '/' + folder + '/data/csv/'\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), 'r', encoding='utf-8') as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            allRows.append(row[0])\n",
    "FileStorage(folder, '').storeInCSV(model + '-compiled', allRows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
